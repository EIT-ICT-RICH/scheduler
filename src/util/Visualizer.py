__author__ = 'frank'

import logging
import socket
import time
import json
from Event import Event
import os
import zmq
import zmq.auth
from zmq.auth.thread import ThreadAuthenticator
from zmq.log.handlers import PUBHandler
import cPickle as pickle

logg = logging.getLogger('RiSCHER')
logg.setLevel(logging.DEBUG)


class FrankFancyStreamingInterface(object):
	"""
	Abstraction layer to the graph streamer as well as the central logger
	Uses direct (non encrypted) socket connection to the streaming server
	It uses an (encrypted) zeromq connection to the logger
	"""

	ConvertStatus = {
		"Cells" : {
			0 : 5, #removing
			1 : 4, #allocating
			2 : 6  #blacklisting
		}
	}

	#TODO: give every scheduler an unique topic to easily distinguish between them on the queue
	def __init__(self,VisualizerHost="localhost", ZeromqHost = "*", KeyFolder=".", root_id=None):
		"""
		Calls internal methods to open the connections to both the Active Live visualizer and the logger

		:param VisualizerHost: The ip of the FrankFancyGraphStreamer
		:type VisualizerHost: str
		:param ZeromqHost: which interface the zeromq service needs to bind too ("*" for all interfaces)
		:type ZeromqHost: str
		:param KeyFolder: The folder with all the keys, as generated by generate_certificates.py
		:type KeyFolder: str
		:param root_id: the root of the network: LBR
		:type root_id: str
		:return:
		"""

		self.Active = None
		self.Logger = None
		self.EventId = 0
		self.Name = "Scheduler1" #used as topic on the queue

		self._connectLogger(ZeromqHost, KeyFolder)
		self._connectVisualizer(VisualizerHost, root_id)

	def _connectVisualizer(self, Host="localhost", root_id=""):
		"""
		Connect to the Active Live Visualizer

		:param Host: The ip of the FrankFancyGraphStreamer
		:param root_id: the ip6 address of the root node of the network
		:return:
		"""
		try:
			logg.debug("Connecting Streaming Interface to Active Viewer")
			self.Active = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
			self.Active.connect((Host, 600))
			self.Active.sendall(root_id)
		except:
			logg.debug("Connection to Active Viewer failed!")
			self.Active = None

	def _connectLogger(self,Host="localhost", KeyFolder="."):
		"""
		Open a zeromq queue with publisher service

		:param Host: which interface the zeromq service needs to bind too ("*" for all interfaces)
		:param KeyFolder: The folder with the privatekey of the publisher service
		:return:
		"""
		#TODO: error handling on certificates missing and stuff
		#TODO: expose more security options such as white/blacklisting ips and domain filtering
		context = zmq.Context()
		auth = ThreadAuthenticator(context)
		auth.start()
		# auth.allow('127.0.0.1')
		auth.configure_curve(domain='*', location=os.path.join(KeyFolder, "public_keys"))

		self.Logger = context.socket(zmq.PUB)
		server_secret_file = os.path.join(*["private_keys", "server.key_secret"])
		server_public, server_secret = zmq.auth.load_certificate(server_secret_file)
		socket.curve_secretkey = server_secret
		socket.curve_publickey = server_public
		socket.curve_server = True
		socket.bind("tcp://*:%s" % 600)

	def SendActiveJson(self,data):
		"""
		Sends an object as json encoded to the Active Live Viewer

		:param data: the object to be send
		:return:
		"""
		if self.Active is not None:
			logg.debug("Sending json data to Active: " + json.dumps(data))
			self.Active.sendall(json.dumps(data))

	def PublishLogging(self,LoggingName="zmq.auth", root_topic="zmq.auth"):
		"""
		Publishes the given python logger to the publishing service

		:param LoggingName: Name of the python logger service
		:type LoggingName: str
		:param root_topic: the topic given with message. is appended with .<LEVEL>
		:type root_topic: str
		:return:
		"""
		handler = PUBHandler(self.Logger)
		handler.root_topic = root_topic
		handler.formatters[logging.DEBUG] = logging.Formatter(fmt='%(asctime)s\t%(levelname)s: %(message)s', datefmt='%H:%M:%S')
		handler.formatters[logging.INFO] = logging.Formatter(fmt='%(asctime)s\t%(levelname)s: %(message)s', datefmt='%H:%M:%S')
		l = logging.getLogger(LoggingName)
		l.addHandler(handler)

	def ChangeCell(self, who, slotoffs, channeloffs, frame, ID, status):
		"""
		Notifies all active services about the changes to a cell in the schedule matrix

		:param who: The node in which the cell is changed
		:type who: :class: `node.NodeID`
		:param slotoffs: slot offset
		:param channeloffs: channel offset
		:param frame: frame name
		:param ID: local cell id
		:param status: new status of the cell
		:return:
		"""
		if self.Active is not None:
			logg.debug("Sending ChangeCell to active viewer")
			self.Active.sendall(json.dumps(["changecell",{"who": who, "channeloffs":channeloffs, "slotoffs":slotoffs, "frame":frame, "id":ID, "status":status}]))
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending ChangeCell to logger, EventID:" + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"		: self.EventId,
			# 	"SubjectId" 	: self.ConvertStatus["Cells"][status],
			# 	"InfoString" 	: json.dumps({"who": who, "channeloffs":channeloffs, "slotoffs":slotoffs, "frame":frame, "id":ID})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, self.ConvertStatus["Cells"][status], time.time(), json.dumps({"who": who, "channeloffs":channeloffs, "slotoffs":slotoffs, "frame":frame, "id":ID})))])

	def DumpDotData(self, root_id, dotdata):
		"""
		dumps an entire dot file to the active viewer. This is not used for the logger

		:param root_id: ip6 of the LBR
		:type root_id: str
		:param dotdata: the dotfile to be send
		:return:
		"""
		# packet = "[\"" + str(self.root_id) + " at " + time.strftime("%Y-%m-%d %H:%M:%S") + "\"," + json.dumps(dotdata) + "]"
		if self.Active is not None:
			logg.debug("Sending dotdata")
			self.Active.sendall(bytearray("[\"" + root_id + " at " + time.strftime("%Y-%m-%d %H:%M:%S") + "\"," + dotdata + "]"))

	def AddNode(self, node_id, parent):
		"""
		Sends a notification of joining node to the logger

		:param node_id: ip6 of the node
		:type node_id: str
		:param parent: ip6 of the parent node
		:type parent: str
		:return:
		"""
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending Addnode to logger, EventID:" + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"	: self.EventId,
			# 	"SubjectId"	: 0,
			# 	"InfoString": json.dumps({"node_id" : node_id, "parent" : parent})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, 0, time.time(), json.dumps({"node_id" : node_id, "parent" : parent})))])

	def RewireNode(self, node_id, old_parent, new_parent):
		"""
		Notifies the logger of a rewire that happened in the network

		:param node_id: ip6 of the node that has rewired
		:param old_parent: ip6 of the old parent
		:param new_parent: ip6 of the new parent
		:return:
		"""
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending RewireNode to logger, EventID: " + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"	: self.EventId,
			# 	"SubjectId"	: 2,
			# 	"InfoString": json.dumps({"node_id" : node_id, "old_parent" : old_parent, "new_parent" : new_parent})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, 2, time.time(), json.dumps({"node_id" : node_id, "old_parent" : old_parent, "new_parent" : new_parent})))])

	def RemoveNode(self, node_id):
		"""
		Notifies the logger of a disconnected node

		:param node_id: ip6 of the node that has disconnected
		:return:
		"""
		if self.Logger is not None:
			self.EventId += 1
			logg.debug("Sending RemoveNode to logger, EventID: " + str(self.EventId))
			# self.Logger.send_multipart([self.Name.encode(), pickle.dumps({
			# 	"EventId"	: self.EventId,
			# 	"SubjectId"	: 1,
			# 	"InfoString": json.dumps({"node_id" : node_id})
			# })])
			self.Logger.send_multipart([self.Name.encode(), pickle.dumps(Event(self.EventId, 1, time.time(), json.dumps({"node_id" : node_id})))])